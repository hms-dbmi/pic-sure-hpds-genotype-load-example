{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the PIC-SURE-HPDS client library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "#!{sys.executable} -m pip uninstall git+https://github.com/hms-dbmi/pic-sure-python-client.git    \n",
    "#!{sys.executable} -m pip uninstall git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade git+https://github.com/hms-dbmi/pic-sure-python-client.git    \n",
    "!{sys.executable} -m pip install --upgrade git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are connecting directly to the HPDS resource, bypassing all security. This should never be made possible in an instance holding private data. We do this by creating a Resource Adaptor for HDPS that bypasses PIC-SURE and get the only resource it has access to. \n",
    "\n",
    "# An HPDS instance should always be hosted behind a PIC-SURE API and PIC-SURE Auth Micro-App instance if it has any privacy concern. \n",
    "\n",
    "# This is only for the example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import pandas as pd\n",
    "import PicSureHpdsLib\n",
    "adapter = PicSureHpdsLib.BypassAdapter(\"http://pic-sure-hpds-1kgenome:8080/PIC-SURE\")\n",
    "resource = adapter.useResource()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To see what is possible using this resource adaptor let's look at the interactive documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resource.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have a couple things we can do, we can access the data dictionary, or we can run a query. First let's see the annotations that were loaded from the INFO column of the source VCF. To do this we search the data dictionary for everything(empty string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dictionary = resource.dictionary().find(\"\")\n",
    "data_dictionary.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have seen what kind of data is indexed in the dictionary, let's figure out how to query it. We strive to document each function of the client library with interactive help. This is the help for the query() object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resource.query().help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In order to run a query, we generally want to filter the patients in scope. We can use the data dictionary to create filters for this. For example, if we want to filter by a categorical variable such as the source call set variable, we just add a filter to our query and get a count of patients by calling getCount() on the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CS_SVA_umary = resource.query()\n",
    "CS_SVA_umary.filter().add(\"VT\",[\"SNP\"])\n",
    "CS_SVA_umary.getCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we want to filter by a numerical variable such as the estimated allele frequency we can add a numerical range filter then call getCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AF_001 = resource.query()\n",
    "AF_001.filter().add(\"AF\", min=.000, max=.001)\n",
    "AF_001.getCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Something to be careful of when using numerical range filtering is that it is really easy to end up building a filter that includes all patients. Everyone has at least 1 rare variant, so we get all patients back. This particular filter involves 141,362 different variants. The total size of our dataset is 2504 patients, and at least 1 patient has every one of the variants in our dataset.\n",
    "# To make this a more useful(and faster) query we should add additional filters, let's combine the 2 previous filters. This will only include variants that have source call set value of SVA_umary and an estimated allele frequency in the general population of less than .1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CS_SVA_umary = resource.query()\n",
    "CS_SVA_umary.filter().add(\"CS\",[\"SVA_umary\"])\n",
    "CS_SVA_umary.filter().add(\"AF\", min=.000, max=.001)\n",
    "CS_SVA_umary.getCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also query on a specific variant of interest and specific zygosities for that variant. For example, let's see how many subjects have homozygous G->A for offset 19073032 on chromosome 14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "homozygous_G_A = resource.query()\n",
    "homozygous_G_A.filter().add(\"14,19073032,G,A\",[\"1/1\"])\n",
    "homozygous_G_A.getCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also see how many subjects have either homozygous or heterozygous G->A for offset 19073032 on chromosome 14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "any_G_A = resource.query()\n",
    "any_G_A.filter().add(\"14,19073032,G,A\",[\"1/1\", \"0/1\"])\n",
    "any_G_A.getCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also find patients who have both homozygous 14,19007199,C,T and heterozygous 14,19073032,G,A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "two_variants_and = resource.query()\n",
    "two_variants_and.filter().add(\"14,19007199,C,T\",[\"1/1\"])\n",
    "two_variants_and.filter().add(\"14,19073032,G,A\",[\"0/1\"])\n",
    "two_variants_and.getCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we are interested in the ids for those patients, we can get the results dataframe for the query also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "two_variants_and.getResultsDataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we had phenotype data we could probably come up with a better use-case here, but we will save that for another example. Let's create two subsets and find the counts for each of those subsets for 2600 different variants.\n",
    "# Subset A are people who are homozygous-reference for 14,19073032,G,A\n",
    "# Subset B are people who have any copies of the variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chr14_19073032_G_only = resource.query()\n",
    "chr14_19073032_G_only.filter().add(\"14,19073032,G,A\",[\"0/0\"])\n",
    "chr14_19073032_G_only.getCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chr14_19073032_G_A = resource.query()\n",
    "chr14_19073032_G_A.filter().add(\"14,19073032,G,A\",[\"1/1\",\"0/1\"])\n",
    "chr14_19073032_G_A.getCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's see how many subjects in each subset have each variant in a list of 2600 variants of our choosing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variants = []\n",
    "file = open('2600variants.txt', 'r')\n",
    "\n",
    "for variant in file:\n",
    "    variants.append(variant.replace('\\n', ''))\n",
    "    \n",
    "chr14_19073032_G_only.crosscounts().clear()\n",
    "chr14_19073032_G_only.crosscounts().add(variants)\n",
    "chr14_19073032_G_only_counts = chr14_19073032_G_only.getCrossCounts()\n",
    "\n",
    "chr14_19073032_G_A.crosscounts().clear()\n",
    "chr14_19073032_G_A.crosscounts().add(variants)\n",
    "chr14_19073032_G_A_counts = chr14_19073032_G_A.getCrossCounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countsDataframe = pd.DataFrame([chr14_19073032_G_only_counts,chr14_19073032_G_A_counts])\n",
    "countsDataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Those counts seem a bit disproportionate to me, maybe there is a correlation between 14,19073032,G,A and 14,19000141,T,C but I'll leave that up to you to figure out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countsDataframe['14,19000141,T,C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# You can also run this same query for the allVariants.txt file, which has 360k variants. It will take only a few minutes if you do.\n",
    "\n",
    "# Please also check out our phenotype example here https://github.com/hms-dbmi/pic-sure-hpds-phenotype-load-example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
